{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Preprocessing\n",
    "## Submitted by:\n",
    "### Vibhakar Gupta(189301098)\n",
    "### Mrityunjoy Chowdhury(189301071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\" India (Hindi: Bhārat), officially the Republic of India (Hindi: Bhārat Gaṇarājya),[23] is a country in South Asia. It is the second-most populous country, the seventh-largest country by land area, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vibhakar\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "words = nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' India (Hindi: Bhārat), officially the Republic of India (Hindi: Bhārat Gaṇarājya),[23] is a country in South Asia.',\n",
       " 'It is the second-most populous country, the seventh-largest country by land area, and the most populous democracy in the world.',\n",
       " 'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.',\n",
       " 'In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Vibhakar\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['india ( hindi : bhārat ) , offici republ india ( hindi : bhārat gaṇarājya ) , [ 23 ] countri south asia .',\n",
       " 'It second-most popul countri , seventh-largest countri land area , popul democraci world .',\n",
       " 'bound indian ocean south , arabian sea southwest , bay bengal southeast , share land border pakistan west ; [ f ] china , nepal , bhutan north ; bangladesh myanmar east .',\n",
       " 'In indian ocean , india vicin sri lanka maldiv ; andaman nicobar island share maritim border thailand indonesia .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Vibhakar\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Vibhakar\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['India ( Hindi : Bhārat ) , officially Republic India ( Hindi : Bhārat Gaṇarājya ) , [ 23 ] country South Asia .',\n",
       " 'It second-most populous country , seventh-largest country land area , populous democracy world .',\n",
       " 'Bounded Indian Ocean south , Arabian Sea southwest , Bay Bengal southeast , share land border Pakistan west ; [ f ] China , Nepal , Bhutan north ; Bangladesh Myanmar east .',\n",
       " 'In Indian Ocean , India vicinity Sri Lanka Maldives ; Andaman Nicobar Islands share maritime border Thailand Indonesia .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count - Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23', 'and', 'andaman', 'arabian', 'area', 'asia', 'bangladesh', 'bay', 'bengal', 'bhutan', 'bhārat', 'border', 'borders', 'bounded', 'by', 'china', 'country', 'democracy', 'east', 'gaṇarājya', 'hindi', 'in', 'india', 'indian', 'indonesia', 'is', 'islands', 'it', 'its', 'land', 'lanka', 'largest', 'maldives', 'maritime', 'most', 'myanmar', 'nepal', 'nicobar', 'north', 'ocean', 'of', 'officially', 'on', 'pakistan', 'populous', 'republic', 'sea', 'second', 'seventh', 'share', 'shares', 'south', 'southeast', 'southwest', 'sri', 'thailand', 'the', 'to', 'vicinity', 'west', 'with', 'world']\n",
      "[[1 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 0 0 1 2 1 2 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 2 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 2 0\n",
      "  0 0 0 0 0 0 0 0 2 0 0 1 1 0 0 0 0 0 0 0 4 0 0 0 0 1]\n",
      " [0 4 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      "  1 0 1 1 1 0 3 1 0 0 1 0 0 0 1 1 1 1 0 0 9 3 0 1 1 0]\n",
      " [0 3 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 0 1 0 1 0 1 1 0 0\n",
      "  0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 3 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "vectorizer = CountVectorizer()\n",
    "voc = vectorizer.fit_transform(sentences)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(voc.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23', 'and', 'andaman', 'arabian', 'area', 'asia', 'bangladesh', 'bay', 'bengal', 'bhutan', 'bhārat', 'border', 'borders', 'bounded', 'by', 'china', 'country', 'democracy', 'east', 'gaṇarājya', 'hindi', 'in', 'india', 'indian', 'indonesia', 'is', 'islands', 'it', 'its', 'land', 'lanka', 'largest', 'maldives', 'maritime', 'most', 'myanmar', 'nepal', 'nicobar', 'north', 'ocean', 'of', 'officially', 'on', 'pakistan', 'populous', 'republic', 'sea', 'second', 'seventh', 'share', 'shares', 'south', 'southeast', 'southwest', 'sri', 'thailand', 'the', 'to', 'vicinity', 'west', 'with', 'world']\n",
      "[[0.23424854 0.         0.         0.         0.         0.23424854\n",
      "  0.         0.         0.         0.         0.46849707 0.\n",
      "  0.         0.         0.         0.         0.18468424 0.\n",
      "  0.         0.23424854 0.46849707 0.14951781 0.36936848 0.\n",
      "  0.         0.14951781 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14951781 0.23424854\n",
      "  0.         0.         0.         0.23424854 0.         0.\n",
      "  0.         0.         0.         0.18468424 0.         0.\n",
      "  0.         0.         0.1222406  0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.13047892 0.         0.         0.20442044 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16116743 0.         0.32233485 0.20442044\n",
      "  0.         0.         0.         0.13047892 0.         0.\n",
      "  0.         0.13047892 0.         0.16116743 0.         0.16116743\n",
      "  0.         0.20442044 0.         0.         0.40884089 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.40884089 0.         0.         0.20442044\n",
      "  0.20442044 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.42670027 0.         0.         0.\n",
      "  0.         0.20442044]\n",
      " [0.         0.30661966 0.         0.12009474 0.         0.\n",
      "  0.12009474 0.12009474 0.12009474 0.12009474 0.         0.\n",
      "  0.12009474 0.12009474 0.09468407 0.12009474 0.         0.\n",
      "  0.12009474 0.         0.         0.         0.         0.09468407\n",
      "  0.         0.         0.         0.09468407 0.         0.09468407\n",
      "  0.         0.         0.         0.         0.         0.12009474\n",
      "  0.12009474 0.         0.12009474 0.09468407 0.07665491 0.\n",
      "  0.36028421 0.12009474 0.         0.         0.12009474 0.\n",
      "  0.         0.         0.12009474 0.09468407 0.12009474 0.12009474\n",
      "  0.         0.         0.56403374 0.36028421 0.         0.12009474\n",
      "  0.09468407 0.        ]\n",
      " [0.         0.39047592 0.20391866 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20391866\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.26031728 0.16077181 0.16077181\n",
      "  0.20391866 0.13015864 0.20391866 0.         0.20391866 0.\n",
      "  0.20391866 0.         0.20391866 0.20391866 0.         0.\n",
      "  0.         0.20391866 0.         0.16077181 0.13015864 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20391866 0.         0.         0.         0.\n",
      "  0.20391866 0.20391866 0.31923965 0.         0.20391866 0.\n",
      "  0.16077181 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "vectorizer = TfidfVectorizer()\n",
    "voc = vectorizer.fit_transform(sentences)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(voc.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      "  1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1]]\n",
      "['the', ',', 'and', '.', 'India', 'of', 'is', 'country', 'in', 'on', 'to', ';', '(', 'Hindi', ':', 'Bhārat', ')', '[', ']', 'a', 'populous', 'by', 'land', 'Indian', 'Ocean', 'with', 'officially', 'Republic', 'Gaṇarājya', '23', 'South', 'Asia', 'It', 'second-most', 'seventh-largest', 'area', 'most', 'democracy', 'world', 'Bounded', 'south', 'Arabian', 'Sea', 'southwest', 'Bay', 'Bengal', 'southeast', 'it', 'shares', 'borders', 'Pakistan', 'west', 'f', 'China', 'Nepal', 'Bhutan', 'north', 'Bangladesh', 'Myanmar', 'east', 'In', 'vicinity', 'Sri', 'Lanka', 'Maldives', 'its', 'Andaman', 'Nicobar', 'Islands', 'share', 'maritime', 'border', 'Thailand', 'Indonesia']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "words = nltk.word_tokenize(paragraph)\n",
    "word_to_count = {}\n",
    "for word in words:\n",
    "    if word not in word_to_count.keys():\n",
    "        word_to_count[word] = 1\n",
    "    else:\n",
    "        word_to_count[word] = word_to_count[word] + 1\n",
    "freq_words = heapq.nlargest(100, word_to_count, key=word_to_count.get)    \n",
    "\n",
    "X = [] \n",
    "for sentence in sentences: \n",
    "    vector = [] \n",
    "    for word in freq_words: \n",
    "        if word in nltk.word_tokenize(sentence): \n",
    "            vector.append(1) \n",
    "        else: \n",
    "            vector.append(0) \n",
    "    X.append(vector) \n",
    "X = np.asarray(X) \n",
    "print(X)\n",
    "print(freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
